{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:32.944654Z",
     "start_time": "2020-02-23T11:20:32.922160Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:33.424699Z",
     "start_time": "2020-02-23T11:20:33.391656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>current_date</th>\n",
       "      <th>current_time</th>\n",
       "      <th>source_name</th>\n",
       "      <th>destination_name</th>\n",
       "      <th>train_name</th>\n",
       "      <th>target</th>\n",
       "      <th>country_code_source</th>\n",
       "      <th>longitude_source</th>\n",
       "      <th>latitude_source</th>\n",
       "      <th>mean_halt_times_source</th>\n",
       "      <th>country_code_destination</th>\n",
       "      <th>longitude_destination</th>\n",
       "      <th>latitude_destination</th>\n",
       "      <th>mean_halt_times_destination</th>\n",
       "      <th>current_year</th>\n",
       "      <th>current_week</th>\n",
       "      <th>current_day</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>isfywypmkqqhyft</td>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>08:05:51 PM</td>\n",
       "      <td>station$147</td>\n",
       "      <td>station$1</td>\n",
       "      <td>ICZVZS</td>\n",
       "      <td>high</td>\n",
       "      <td>whber</td>\n",
       "      <td>4.356801</td>\n",
       "      <td>50.845658</td>\n",
       "      <td>634.16474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mqsfxyvuqpbwomk</td>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>08:06:11 PM</td>\n",
       "      <td>station$147</td>\n",
       "      <td>station$1</td>\n",
       "      <td>ICZVZS</td>\n",
       "      <td>high</td>\n",
       "      <td>whber</td>\n",
       "      <td>4.356801</td>\n",
       "      <td>50.845658</td>\n",
       "      <td>634.16474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alspwwtbdvqsgby</td>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>08:08:57 PM</td>\n",
       "      <td>station$147</td>\n",
       "      <td>station$1</td>\n",
       "      <td>ICZVZS</td>\n",
       "      <td>high</td>\n",
       "      <td>whber</td>\n",
       "      <td>4.356801</td>\n",
       "      <td>50.845658</td>\n",
       "      <td>634.16474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>szitxhhqduyrqpg</td>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>08:09:08 PM</td>\n",
       "      <td>station$147</td>\n",
       "      <td>station$1</td>\n",
       "      <td>ICZVZS</td>\n",
       "      <td>high</td>\n",
       "      <td>whber</td>\n",
       "      <td>4.356801</td>\n",
       "      <td>50.845658</td>\n",
       "      <td>634.16474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>krisdqzczivvwcp</td>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>08:11:01 PM</td>\n",
       "      <td>station$147</td>\n",
       "      <td>station$1</td>\n",
       "      <td>ICZVZS</td>\n",
       "      <td>high</td>\n",
       "      <td>whber</td>\n",
       "      <td>4.356801</td>\n",
       "      <td>50.845658</td>\n",
       "      <td>634.16474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_code current_date current_time  source_name destination_name  \\\n",
       "0  isfywypmkqqhyft   2016-07-27  08:05:51 PM  station$147        station$1   \n",
       "1  mqsfxyvuqpbwomk   2016-07-27  08:06:11 PM  station$147        station$1   \n",
       "2  alspwwtbdvqsgby   2016-07-27  08:08:57 PM  station$147        station$1   \n",
       "3  szitxhhqduyrqpg   2016-07-27  08:09:08 PM  station$147        station$1   \n",
       "4  krisdqzczivvwcp   2016-07-27  08:11:01 PM  station$147        station$1   \n",
       "\n",
       "  train_name target country_code_source  longitude_source  latitude_source  \\\n",
       "0     ICZVZS   high               whber          4.356801        50.845658   \n",
       "1     ICZVZS   high               whber          4.356801        50.845658   \n",
       "2     ICZVZS   high               whber          4.356801        50.845658   \n",
       "3     ICZVZS   high               whber          4.356801        50.845658   \n",
       "4     ICZVZS   high               whber          4.356801        50.845658   \n",
       "\n",
       "   mean_halt_times_source country_code_destination  longitude_destination  \\\n",
       "0               634.16474                      NaN                    NaN   \n",
       "1               634.16474                      NaN                    NaN   \n",
       "2               634.16474                      NaN                    NaN   \n",
       "3               634.16474                      NaN                    NaN   \n",
       "4               634.16474                      NaN                    NaN   \n",
       "\n",
       "   latitude_destination  mean_halt_times_destination  current_year  \\\n",
       "0                   NaN                          NaN          2016   \n",
       "1                   NaN                          NaN          2016   \n",
       "2                   NaN                          NaN          2016   \n",
       "3                   NaN                          NaN          2016   \n",
       "4                   NaN                          NaN          2016   \n",
       "\n",
       "   current_week current_day  is_weekend  \n",
       "0            30   Wednesday       False  \n",
       "1            30   Wednesday       False  \n",
       "2            30   Wednesday       False  \n",
       "3            30   Wednesday       False  \n",
       "4            30   Wednesday       False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping all rows with NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:34.225944Z",
     "start_time": "2020-02-23T11:20:34.216735Z"
    }
   },
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:34.661062Z",
     "start_time": "2020-02-23T11:20:34.651233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1250, 19)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping columns with many distinct levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:35.758121Z",
     "start_time": "2020-02-23T11:20:35.751583Z"
    }
   },
   "outputs": [],
   "source": [
    "data.drop(['destination_name','id_code','source_name','train_name','country_code_destination', 'country_code_source'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:36.209388Z",
     "start_time": "2020-02-23T11:20:36.200434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "current_date                    object\n",
       "current_time                    object\n",
       "target                          object\n",
       "longitude_source               float64\n",
       "latitude_source                float64\n",
       "mean_halt_times_source         float64\n",
       "longitude_destination          float64\n",
       "latitude_destination           float64\n",
       "mean_halt_times_destination    float64\n",
       "current_year                     int64\n",
       "current_week                     int64\n",
       "current_day                     object\n",
       "is_weekend                        bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:36.918649Z",
     "start_time": "2020-02-23T11:20:36.765218Z"
    }
   },
   "outputs": [],
   "source": [
    "data['current_hour'] = pd.to_datetime(data.current_time).dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping current_date, year, current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:37.530948Z",
     "start_time": "2020-02-23T11:20:37.525230Z"
    }
   },
   "outputs": [],
   "source": [
    "data.drop(['current_date','current_year','current_time','current_week'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:39.059227Z",
     "start_time": "2020-02-23T11:20:39.052959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'longitude_source', 'latitude_source',\n",
       "       'mean_halt_times_source', 'longitude_destination',\n",
       "       'latitude_destination', 'mean_halt_times_destination', 'current_day',\n",
       "       'is_weekend', 'current_hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering - Spacial analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:40.261610Z",
     "start_time": "2020-02-23T11:20:40.254652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'longitude_source', 'latitude_source',\n",
       "       'mean_halt_times_source', 'longitude_destination',\n",
       "       'latitude_destination', 'mean_halt_times_destination', 'current_day',\n",
       "       'is_weekend', 'current_hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:40.805302Z",
     "start_time": "2020-02-23T11:20:40.800755Z"
    }
   },
   "outputs": [],
   "source": [
    "spacial_data = data[['longitude_destination', 'latitude_destination', 'longitude_source', 'latitude_source']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing spacial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:42.156612Z",
     "start_time": "2020-02-23T11:20:42.147523Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "spacial_data = pd.DataFrame(scaler.fit_transform(spacial_data), columns=spacial_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:44.459807Z",
     "start_time": "2020-02-23T11:20:43.056313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "wss = {}\n",
    "for k in range(2, 15):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(spacial_data)\n",
    "    wss[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\n",
    "plt.figure()\n",
    "plt.plot(list(wss.keys()), list(wss.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"wss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:45.199453Z",
     "start_time": "2020-02-23T11:20:45.119251Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans_object = KMeans(n_clusters=4, random_state=1240)\n",
    "kmeans_object.fit(spacial_data)\n",
    "data['cluster'] = kmeans_object.predict(spacial_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoupling target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:47.072931Z",
     "start_time": "2020-02-23T11:20:47.065982Z"
    }
   },
   "outputs": [],
   "source": [
    "y = data['target']\n",
    "X = data[data.columns.difference(['target'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:49.346162Z",
     "start_time": "2020-02-23T11:20:49.331958Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=99, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:51.259795Z",
     "start_time": "2020-02-23T11:20:51.231892Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:20:56.293595Z",
     "start_time": "2020-02-23T11:20:56.282678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 16)\n",
      "(250, 16)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:23:09.637300Z",
     "start_time": "2020-02-23T11:23:09.613260Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "full_scaler = MinMaxScaler()\n",
    "full_scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(full_scaler.transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(full_scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:26:06.593955Z",
     "start_time": "2020-02-23T11:26:06.384362Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raju4789/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/raju4789/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[133 108  60]\n",
      " [ 89 283  53]\n",
      " [ 87 123  64]]\n",
      "[[29 36 10]\n",
      " [22 70 14]\n",
      " [18 34 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.43      0.44      0.44       301\n",
      "         low       0.55      0.67      0.60       425\n",
      "      medium       0.36      0.23      0.28       274\n",
      "\n",
      "    accuracy                           0.48      1000\n",
      "   macro avg       0.45      0.45      0.44      1000\n",
      "weighted avg       0.46      0.48      0.47      1000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.42      0.39      0.40        75\n",
      "         low       0.50      0.66      0.57       106\n",
      "      medium       0.41      0.25      0.31        69\n",
      "\n",
      "    accuracy                           0.46       250\n",
      "   macro avg       0.44      0.43      0.43       250\n",
      "weighted avg       0.45      0.46      0.45       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "logistic = LogisticRegression(class_weight='balanced')\n",
    "logistic.fit(X_train, y_train)\n",
    "\n",
    "logistic_train_preds = logistic.predict(X_train)\n",
    "logistic_test_preds = logistic.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_train, logistic_train_preds))\n",
    "print(confusion_matrix(y_test, logistic_test_preds))\n",
    "\n",
    "print(classification_report(y_train, logistic_train_preds))\n",
    "print(classification_report(y_test, logistic_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T11:39:09.586572Z",
     "start_time": "2020-02-23T11:39:09.386976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149  83  69]\n",
      " [ 96 255  74]\n",
      " [ 79  85 110]]\n",
      "[[30 23 22]\n",
      " [34 53 19]\n",
      " [21 28 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.46      0.50      0.48       301\n",
      "         low       0.60      0.60      0.60       425\n",
      "      medium       0.43      0.40      0.42       274\n",
      "\n",
      "    accuracy                           0.51      1000\n",
      "   macro avg       0.50      0.50      0.50      1000\n",
      "weighted avg       0.51      0.51      0.51      1000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.35      0.40      0.38        75\n",
      "         low       0.51      0.50      0.50       106\n",
      "      medium       0.33      0.29      0.31        69\n",
      "\n",
      "    accuracy                           0.41       250\n",
      "   macro avg       0.40      0.40      0.40       250\n",
      "weighted avg       0.41      0.41      0.41       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm1 = SVC(class_weight='balanced', kernel='rbf', C=0.2, gamma=1)\n",
    "svm1.fit(X_train, y_train)\n",
    "\n",
    "logistic_train_preds = svm1.predict(X_train)\n",
    "logistic_test_preds = svm1.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_train, logistic_train_preds))\n",
    "print(confusion_matrix(y_test, logistic_test_preds))\n",
    "\n",
    "print(classification_report(y_train, logistic_train_preds))\n",
    "print(classification_report(y_test, logistic_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
